\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{apacite}
\usepackage{listings}

% APA Style Cover Page Adjustments
\title{
    \vspace{2in} % Adjust vertical space as needed
    Final Term Project - Google Play Store
    \vspace{1.5in} % Additional vertical space before author name
}
\author{
    Baiyi Zhang \\
    CS 5805: Machine Learning I \\
    Dr. Reza Jafari \\
    \vspace{1.5in} % Additional vertical space before date
    December 7, 2023 \\% Replace with specific date if necessary 
}
\date{} % Empty date to avoid duplication

\begin{document}

% Create the title page
\maketitle
\thispagestyle{empty} % No header or footer on title page
\newpage
\pagenumbering{roman}
\tableofcontents
\newpage
\listoffigures
\newpage
\pagenumbering{arabic}
% Include sections
\include{1_Abstract}
\include{2_Introduction}
\include{3_Dataset_Description}
\include{4_Phase_1}
\include{5_Phase_2}

\bibliographystyle{apacite}
\bibliography{docs/tex/ref}
% \renewcommand{\arraystretch}{1.5} % Adjust to your needs
% \begin{adjustbox}{width=\textwidth,center}
% \begin{tabular}{cccccc|c}
% Classifier & Precision & Recall & Specificity & F1 Score & AUC & Confusion Matrix \\
% Decision Tree Pre-pruning & 0.804 & 0.770 & 0.812 & 0.786 & 0.791 & $\begin{matrix} 13032 & 3020 \\ 3699 & 12352 \end{matrix}$ \\
% Decision Tree Post-pruning & 0.812 & 0.727 & 0.831 & 0.767 & 0.779 & $\begin{matrix} 13345 & 2707 \\ 4381 & 11670 \end{matrix}$ \\
% Logistic Regression & 0.864 & 0.641 & 0.899 & 0.736 & 0.770 & $\begin{matrix} 14437 & 1615 \\ 5756 & 10295 \end{matrix}$ \\
% K-Nearest Neighbors & 0.835 & 0.620 & 0.878 & 0.711 & 0.749 & $\begin{matrix} 14089 & 1963 \\ 6104 & 9947 \end{matrix}$ \\
% Support Vector Machine & 0.875 & 0.672 & 0.904 & 0.760 & 0.788 & $\begin{matrix} 14515 & 1537 \\ 5263 & 10788 \end{matrix}$ \\
% Naive Bayes & 0.918 & 0.442 & 0.960 & 0.597 & 0.701 & $\begin{matrix} 15415 & 637 \\ 8954 & 7097 \end{matrix}$ \\
% Random Forest Bagging & 0.793 & 0.793 & 0.792 & 0.793 & 0.793 & $\begin{matrix} 12719 & 3333 \\ 3320 & 12731 \end{matrix}$ \\
% Stacking & 0.846 & 0.729 & 0.867 & 0.783 & 0.798 & $\begin{matrix} 13921 & 2131 \\ 4346 & 11705 \end{matrix}$ \\
% Boosting & 0.817 & 0.764 & 0.829 & 0.790 & 0.797 & $\begin{matrix} 13313 & 2739 \\ 3782 & 12269 \end{matrix}$ \\
% Neural Network & 0.824 & 0.767 & 0.836 & 0.794 & 0.802 & $\begin{matrix} 13422 & 2630 \\ 3740 & 12311 \end{matrix}$ \\
% \end{tabular}
% \end{adjustbox}

% \begin{center}
% \begin{tabular}{lclc}
% \toprule
% \textbf{Dep. Variable:}       &   installCount   & \textbf{  R-squared:         } &      0.368   \\
% \textbf{Model:}               &       OLS        & \textbf{  Adj. R-squared:    } &      0.368   \\
% \textbf{Method:}              &  Least Squares   & \textbf{  F-statistic:       } &  1.068e+04   \\
% \textbf{Date:}                & Thu, 30 Nov 2023 & \textbf{  Prob (F-statistic):} &      0.00    \\
% \textbf{Time:}                &     21:26:44     & \textbf{  Log-Likelihood:    } & -1.5240e+05  \\
% \textbf{No. Observations:}    &      128408      & \textbf{  AIC:               } &  3.048e+05   \\
% \textbf{Df Residuals:}        &      128400      & \textbf{  BIC:               } &  3.049e+05   \\
% \textbf{Df Model:}            &           7      & \textbf{                     } &              \\
% \textbf{Covariance Type:}     &    nonrobust     & \textbf{                     } &              \\
% \bottomrule
% \end{tabular}

% \begin{tabular}{lcccccc}
%                               & \textbf{coef} & \textbf{std err} & \textbf{t} & \textbf{P$> |$t$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
% \midrule
% \textbf{const}                &      -0.0412  &        0.003     &   -15.422  &         0.000        &       -0.046    &       -0.036     \\
% \textbf{ratingCount}          &       0.5932  &        0.002     &   247.041  &         0.000        &        0.588    &        0.598     \\
% \textbf{sizeInMB}             &       0.0299  &        0.002     &    12.429  &         0.000        &        0.025    &        0.035     \\
% \textbf{lastUpdateAgeInDays}  &      -0.0734  &        0.002     &   -30.001  &         0.000        &       -0.078    &       -0.069     \\
% \textbf{appAgeInDays}         &       0.0702  &        0.002     &    28.752  &         0.000        &        0.065    &        0.075     \\
% \textbf{rating}               &      -0.0118  &        0.002     &    -5.237  &         0.000        &       -0.016    &       -0.007     \\
% \textbf{isInAppPurchases}     &       0.1568  &        0.005     &    30.019  &         0.000        &        0.147    &        0.167     \\
% \textbf{minAndroidVersion\_7} &      -0.1097  &        0.020     &    -5.503  &         0.000        &       -0.149    &       -0.071     \\
% \bottomrule
% \end{tabular}
% \begin{tabular}{lclc}
% \textbf{Omnibus:}       & 73565.243 & \textbf{  Durbin-Watson:     } &      1.995   \\
% \textbf{Prob(Omnibus):} &    0.000  & \textbf{  Jarque-Bera (JB):  } & 2705960.736  \\
% \textbf{Skew:}          &    2.156  & \textbf{  Prob(JB):          } &       0.00   \\
% \textbf{Kurtosis:}      &   25.072  & \textbf{  Cond. No.          } &       11.3   \\
% \bottomrule
% \end{tabular}
% %\caption{OLS Regression Results}
% \end{center}
% Notes: \newline
%  [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


% \renewcommand{\arraystretch}{3} % Adjust 1.5 to your needs
% \begin{adjustbox}{width=\textwidth,center}
% \begin{tabular}{ccccccc}
% Classifier & Confusion Matrix & Precision & Recall & Specificity & F1 Score & AUC \\
% Decision Tree Pre-pruning & $\begin{bmatrix} 13032 & 3020 \\ 3699 & 12352 \end{bmatrix}$ & 0.804 & 0.770 & 0.812 & 0.786 & 0.791 \\
% Decision Tree Post-pruning & $\begin{bmatrix} 13345 & 2707 \\ 4381 & 11670 \end{bmatrix}$ & 0.812 & 0.727 & 0.831 & 0.767 & 0.779 \\
% Logistic Regression & $\begin{bmatrix} 14437 & 1615 \\ 5756 & 10295 \end{bmatrix}$ & 0.864 & 0.641 & 0.899 & 0.736 & 0.770 \\
% K-Nearest Neighbors & $\begin{bmatrix} 14089 & 1963 \\ 6104 & 9947 \end{bmatrix}$ & 0.835 & 0.620 & 0.878 & 0.711 & 0.749 \\
% Support Vector Machine & $\begin{bmatrix} 14515 & 1537 \\ 5263 & 10788 \end{bmatrix}$ & 0.875 & 0.672 & 0.904 & 0.760 & 0.788 \\
% Naive Bayes & $\begin{bmatrix} 15415 & 637 \\ 8954 & 7097 \end{bmatrix}$ & 0.918 & 0.442 & 0.960 & 0.597 & 0.701 \\
% Random Forest Bagging & $\begin{bmatrix} 12719 & 3333 \\ 3320 & 12731 \end{bmatrix}$ & 0.793 & 0.793 & 0.792 & 0.793 & 0.793 \\
% Stacking & $\begin{bmatrix} 13921 & 2131 \\ 4346 & 11705 \end{bmatrix}$ & 0.846 & 0.729 & 0.867 & 0.783 & 0.798 \\
% Boosting & $\begin{bmatrix} 13313 & 2739 \\ 3782 & 12269 \end{bmatrix}$ & 0.817 & 0.764 & 0.829 & 0.790 & 0.797 \\
% Neural Network & $\begin{bmatrix} 13422 & 2630 \\ 3740 & 12311 \end{bmatrix}$ & 0.824 & 0.767 & 0.836 & 0.794 & 0.802 \\
% \end{tabular}
% \end{adjustbox}


\newpage
% \bibliographystyle{apacite}
% \bibliography{references} % Your references.bib file

\end{document}
